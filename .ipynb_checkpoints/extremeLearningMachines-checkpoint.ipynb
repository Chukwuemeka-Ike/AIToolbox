{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELM Implementations on Multiple Datasets\n",
    "\n",
    "## Extreme Learning Machine\n",
    "The extreme learning machine (ELM) developed by Huang et al. is a linear (in the single-layer case) classifier that was designed to achieve high training speeds. In its simplest form, it is a single-layer feedforward neural network (SLFN) for classification and regression among other functions.\n",
    "\n",
    "Training involves randomizing the input weights and biases, and then performing a matrix inversion to get the output weights. This is done in one step.\n",
    "\n",
    "In this notebook, I train and evaluate multiple types of ELMs on different datasets as a means of familiarizing myself with the algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from scipy import linalg\n",
    "import csv\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris Dataset\n",
    "The first dataset I use is the Iris dataset which consists 3 highly separable classes\n",
    "\n",
    "There are 150 instances in the dataset (50 per class). Each instance is 4-dimensional, with the features described below\n",
    "\n",
    "1. sepal length in cm\n",
    "2. sepal width in cm\n",
    "3. petal length in cm\n",
    "4. petal width in cm\n",
    "5. class: \n",
    "    - Iris Setosa - 1\n",
    "    - Iris Versicolour - 2\n",
    "    - Iris Virginica - 3\n",
    "\n",
    "Armed with this information, we dive right into it. First, we load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Datasets/Iris/iris.data'\n",
    "trainRatio = 0.02\n",
    "\n",
    "# Loads the data given a filename\n",
    "def loadData(filename):\n",
    "    # Create the dataframe then convert it to a\n",
    "    # numpy array\n",
    "    data = pd.read_csv(filename, header=None)\n",
    "    data = data.to_numpy(dtype=None, copy=False)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Splits the data according to the given trainRatio\n",
    "def splitData(data, trainRatio):\n",
    "    # Find which classes are which and separate them\n",
    "    setosa = data[np.where(data[:, -1] == 'Iris-setosa')]\n",
    "    setosa[:,-1] = 1\n",
    "    versicolour = data[np.where(data[:, -1] == 'Iris-versicolor')]\n",
    "    versicolour[:,-1] = 2\n",
    "    virginica = data[np.where(data[:, -1] == 'Iris-virginica')]\n",
    "    virginica[:,-1] = 3\n",
    "\n",
    "    # Shuffle the classed data\n",
    "    np.random.shuffle(setosa)\n",
    "    np.random.shuffle(versicolour)\n",
    "    np.random.shuffle(virginica)\n",
    "\n",
    "    # Take the first trainNum of each class\n",
    "    trainNum = int(trainRatio*setosa.shape[0])\n",
    "    trainSet = setosa[:trainNum,:]\n",
    "    trainSet = np.concatenate((trainSet, versicolour[:trainNum,:]), axis=0)\n",
    "    trainSet = np.concatenate((trainSet, virginica[:trainNum,:]), axis=0)\n",
    "\n",
    "    # Take the rest as test data\n",
    "    testSet = setosa[trainNum:,:]\n",
    "    testSet = np.concatenate((testSet, versicolour[trainNum:,:]), axis=0)\n",
    "    testSet = np.concatenate((testSet, virginica[trainNum:,:]), axis=0)\n",
    "\n",
    "    # Shuffle the train and test sets\n",
    "    np.random.shuffle(trainSet)\n",
    "    np.random.shuffle(testSet)\n",
    "    \n",
    "    # Ensure the data is float32 to avoid indecipherable numpy errors\n",
    "    trainSet = trainSet.astype(np.float32)\n",
    "    testSet = testSet.astype(np.float32)\n",
    "\n",
    "    return trainSet, testSet\n",
    "\n",
    "# Activation function\n",
    "def activate(z, activation):\n",
    "    if activation == 'sigmoid':\n",
    "        return 1/(1+np.exp(-z))\n",
    "    elif activation == 'relu':\n",
    "        return np.maximum(0.0,z)\n",
    "\n",
    "# Compute the accuracy of predictions\n",
    "def accuracy(YPred, YTrue):\n",
    "    sumAcc = 0\n",
    "    if(YPred.size == YTrue.size):\n",
    "        for i in np.arange(YTrue.size):\n",
    "            if(YPred[i] == YTrue[i]):\n",
    "                sumAcc += 1\n",
    "    return (sumAcc/YTrue.size)# * 100\n",
    "\n",
    "# This function thresholds the predictions by setting each\n",
    "# one that is within 0.5 of the class labels to that label\n",
    "def thresholdPreds(YPred, lowerLim, upperLim):\n",
    "    for i in range(lowerLim, upperLim+1):\n",
    "        pos = np.argwhere(np.abs(YPred-i) < 0.5)\n",
    "        for j in pos:\n",
    "            YPred[j] = i\n",
    "    pos = np.argwhere(YPred < lowerLim)\n",
    "    for j in pos:\n",
    "            YPred[j] = lowerLim\n",
    "    pos = np.argwhere(YPred > upperLim)\n",
    "    for j in pos:\n",
    "            YPred[j] = upperLim\n",
    "    return YPred\n",
    "\n",
    "# MAIN FUNCTION\n",
    "def main():\n",
    "    # Load the data\n",
    "    data = loadData(filename)\n",
    "\n",
    "    # Shuffle and split the data\n",
    "    XTrain, XTest = splitData(data, trainRatio)\n",
    "    print(\"trainSet Shape:\", XTrain.shape)\n",
    "    print(\"testSet Shape:\", XTest.shape)\n",
    "\n",
    "    # Separate the data into features and their labels\n",
    "    YTrain = XTrain[:,-1]\n",
    "    XTrain = XTrain[:,:-1]\n",
    "    YTest = XTest[:,-1]\n",
    "    XTest = XTest[:,:-1]\n",
    "\n",
    "    # Now the data is prepped, we can train and \n",
    "    # test the single-layer ELM\n",
    "    nHidden = 2\n",
    "    activation = 'relu'\n",
    "    np.random.seed(0)\n",
    "    inputWeights = np.random.rand(XTrain.shape[1], nHidden)\n",
    "    inputBias = np.random.rand(nHidden, 1)\n",
    "    \n",
    "    # Compute the forward calculation\n",
    "    z = np.matmul(inputWeights.T, XTrain.T) + inputBias\n",
    "    z = z.T\n",
    "\n",
    "    # Activate the computation\n",
    "    H = activate(z, activation)\n",
    "    H.astype(np.double)\n",
    "    print(\"H Shape:\", H.shape)\n",
    "\n",
    "    # Take the pseudoinverse of H and multiply\n",
    "    # it by the labels\n",
    "    Beta = np.matmul(np.linalg.pinv(H), YTrain)\n",
    "    print(\"Beta Shape:\", Beta.shape)\n",
    "\n",
    "    # With this Beta, we should be able to carry out \n",
    "    # the classification task on the test data\n",
    "    z = np.dot(inputWeights.T, XTest.T) + inputBias\n",
    "    z = z.T\n",
    "    H = activate(z, activation)\n",
    "\n",
    "    YPred = np.matmul(H, Beta)\n",
    "\n",
    "    # For multi-class classification, it is important that \n",
    "    # we threshold the data in some manner to select\n",
    "    # its predicted label\n",
    "    YPred = thresholdPreds(YPred, 1, 3)\n",
    "\n",
    "    # Finally, we compute the prediction accuracy\n",
    "    acc = accuracy(YPred, YTest)\n",
    "    print('Prediction Accuracy:{:3.2%}'.format(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainSet Shape: (3, 5)\n",
      "testSet Shape: (147, 5)\n",
      "H Shape: (3, 2)\n",
      "Beta Shape: (2,)\n",
      "Prediction Accuracy:89.12%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
